{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e33c5b0c-d0f1-40c0-b794-3b3471ac73d2",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 7: Clustering and recommender systems\n",
    "### Associated lectures: Lectures 14 and 15\n",
    "\n",
    "**Due date: Thursday, June 16, 2022 at 18:00**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4651888-484b-42a0-95e1-d273e5069205",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086914c2-5de1-414a-8770-23bef9f312d0",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe22cb5-f825-4dba-b5e3-3538f4afe703",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2022s/blob/master/docs/homework_instructions.md).\n",
    "\n",
    "**You may work with a partner on this homework and submit your assignment as a group.** Below are some instructions on working as a group.\n",
    "- The maximum group size is 2.\n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be5b2d-1854-4c63-bcc6-9b6258b7293a",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d8d363-7c31-4381-8a1d-2b2556108916",
   "metadata": {},
   "source": [
    "## Exercise 1: Document clustering toy example <a name=\"1\"></a>\n",
    "<hr>\n",
    "\n",
    "In lecture 14, we looked at a popular application of clustering: customer segmentation. In this homework, we will work on another popular application, [**document clustering**](https://en.wikipedia.org/wiki/Document_clustering). A large amount of unlabeled text data is available out there (e.g., news, recipes, online Q&A), and clustering is a commonly used technique to organize this data in a meaningful way. \n",
    "\n",
    "In this exercise, we will create a toy dataset with sentences from Wikipedia articles and cluster these sentences. In the next exercise, we'll move to a real corpus.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3647bdc9-813a-4270-99cb-a9c88726a860",
   "metadata": {},
   "source": [
    "### 1.1 Sample sentences from Wikipedia articles\n",
    "rubric={points:2}\n",
    "\n",
    "The code below extracts first sentences of Wikipedia articles on a set of queries. You will need the `wikipedia` package installed in the course environment to run the code below. \n",
    "\n",
    "```\n",
    "conda install -n cpsc330 -c conda-forge wikipedia\n",
    "```\n",
    "\n",
    "You also need `nltk` library in the course environment.\n",
    "\n",
    "```\n",
    "conda install -n cpsc330 -c anaconda nltk \n",
    "```\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Run the code below and answer the following question. \n",
    "\n",
    "1. Given this dataset, how many clusters would you expect a clustering algorithm to identify? How would you manually label these clusters?   \n",
    "\n",
    "> *Note: Feel free to experiment with queries of your choice. But stick to the provided list for the final submission so that it's easier for the TAs when they grade your submission.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9821392f-645f-48e5-98ce-b4f69707da10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/emilymiu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c71b2eb-caf0-40f7-b7b0-93f1fadbc548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki query</th>\n",
       "      <th>text</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orange Tree</td>\n",
       "      <td>Citrus × sinensis (sometimes written Citrus sinensis), also known as the sweet oranges, is a commonly cultivated family of oranges that includes blood oranges and navel oranges.</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grapefruit Tree</td>\n",
       "      <td>The grapefruit (Citrus × paradisi) is a subtropical citrus tree known for its relatively large, sour to semi-sweet, somewhat bitter fruit.</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hexagon Shape</td>\n",
       "      <td>In geometry, a hexagon (from Greek ἕξ, hex, meaning \"six\", and γωνία, gonía, meaning \"corner, angle\") is a six-sided polygon or 6-gon.</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English Language</td>\n",
       "      <td>English is a West Germanic language of the Indo-European language family, originally spoken by the inhabitants of early medieval England.</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>German Language</td>\n",
       "      <td>German (Deutsch, pronounced [dɔʏtʃ] (listen)) is a West Germanic language of the Indo-European language family, mainly spoken in Central Europe.</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Planet Jupiter</td>\n",
       "      <td>Jupiter is the fifth planet from the Sun and the largest in the Solar System.</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Planet Venus</td>\n",
       "      <td>Venus is the second planet from the Sun and is named after the Roman goddess of love and beauty.</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         wiki query  \\\n",
       "0  Orange Tree        \n",
       "1  Grapefruit Tree    \n",
       "2  Hexagon Shape      \n",
       "3  English Language   \n",
       "4  German Language    \n",
       "5  Planet Jupiter     \n",
       "6  Planet Venus       \n",
       "\n",
       "                                                                                                                                                                                text  \\\n",
       "0  Citrus × sinensis (sometimes written Citrus sinensis), also known as the sweet oranges, is a commonly cultivated family of oranges that includes blood oranges and navel oranges.   \n",
       "1  The grapefruit (Citrus × paradisi) is a subtropical citrus tree known for its relatively large, sour to semi-sweet, somewhat bitter fruit.                                          \n",
       "2  In geometry, a hexagon (from Greek ἕξ, hex, meaning \"six\", and γωνία, gonía, meaning \"corner, angle\") is a six-sided polygon or 6-gon.                                              \n",
       "3  English is a West Germanic language of the Indo-European language family, originally spoken by the inhabitants of early medieval England.                                           \n",
       "4  German (Deutsch, pronounced [dɔʏtʃ] (listen)) is a West Germanic language of the Indo-European language family, mainly spoken in Central Europe.                                    \n",
       "5  Jupiter is the fifth planet from the Sun and the largest in the Solar System.                                                                                                       \n",
       "6  Venus is the second planet from the Sun and is named after the Roman goddess of love and beauty.                                                                                    \n",
       "\n",
       "   n_words  \n",
       "0  32       \n",
       "1  26       \n",
       "2  36       \n",
       "3  22       \n",
       "4  29       \n",
       "5  16       \n",
       "6  20       "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "queries = [\n",
    "    \"Orange Tree\",\n",
    "    \"Grapefruit Tree\",\n",
    "    \"Hexagon Shape\",\n",
    "    \"English Language\",\n",
    "    \"German Language\",\n",
    "    \"Planet Jupiter\",\n",
    "    \"Planet Venus\"\n",
    "]\n",
    "\n",
    "wiki_dict = {\"wiki query\": [], \"text\": [], \"n_words\": []}\n",
    "for i in range(len(queries)):\n",
    "    sent = sent_tokenize(wikipedia.page(queries[i]).content)[0]\n",
    "    wiki_dict[\"text\"].append(sent)\n",
    "    wiki_dict[\"n_words\"].append(len(word_tokenize(sent)))\n",
    "    wiki_dict[\"wiki query\"].append(queries[i])\n",
    "\n",
    "wiki_df = pd.DataFrame(wiki_dict)\n",
    "wiki_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1506b150-103f-4500-883c-1a85a903061e",
   "metadata": {},
   "source": [
    "Given this dataset, I would expect a clustering algorithm to identify 4 clusters. I would manually label these clusters by examining which queries are similar to each other and which ones are different by looking at the name and text to find similarities in the use of words and sentence structure. Here I can identify four clusters: sentences about fruits, sentences about shapes, sentences about languages, and sentences about planets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f82cba-4642-4872-8b15-e49eab897821",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d98d85-83f3-43c4-aa60-4dc1085d680a",
   "metadata": {},
   "source": [
    "### 1.2 `KMeans` with bag-of-words representation \n",
    "rubric={points:4}\n",
    "\n",
    "We have seen that before we pass text to machine learning models, we need to encode it into a numeric representation. So let's encode our toy dataset above (`wiki_df`) to a numeric representation. \n",
    "\n",
    "First, let's try our good old friend: bag-of-words representation. The code below creates dense bag-of-words representation of Wikipedia sentences from 1.1 with [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Run the code below and answer the following questions. \n",
    "\n",
    "1. Run `KMeans` clustering on the transformed data (`bow_sents`) with K = the number of clusters you identified in 1.1.  \n",
    "2. Examine clustering labels assigned by `KMeans`. Is `KMeans` doing a reasonable job in clustering the sentences? \n",
    "\n",
    "> You can access cluster label assignments using `labels_` attribute of the clustering object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09628f3b-0608-441a-af31-6f8f33ef46d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angle</th>\n",
       "      <th>beauty</th>\n",
       "      <th>bitter</th>\n",
       "      <th>blood</th>\n",
       "      <th>central</th>\n",
       "      <th>citrus</th>\n",
       "      <th>commonly</th>\n",
       "      <th>corner</th>\n",
       "      <th>cultivated</th>\n",
       "      <th>deutsch</th>\n",
       "      <th>...</th>\n",
       "      <th>spoken</th>\n",
       "      <th>subtropical</th>\n",
       "      <th>sun</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tree</th>\n",
       "      <th>venus</th>\n",
       "      <th>west</th>\n",
       "      <th>written</th>\n",
       "      <th>γωνία</th>\n",
       "      <th>ἕξ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   angle  beauty  bitter  blood  central  citrus  commonly  corner  \\\n",
       "0  0      0       0       1      0        2       1         0        \n",
       "1  0      0       1       0      0        2       0         0        \n",
       "2  1      0       0       0      0        0       0         1        \n",
       "3  0      0       0       0      0        0       0         0        \n",
       "4  0      0       0       0      1        0       0         0        \n",
       "5  0      0       0       0      0        0       0         0        \n",
       "6  0      1       0       0      0        0       0         0        \n",
       "\n",
       "   cultivated  deutsch  ...  spoken  subtropical  sun  sweet  tree  venus  \\\n",
       "0  1           0        ...  0       0            0    1      0     0       \n",
       "1  0           0        ...  0       1            0    1      1     0       \n",
       "2  0           0        ...  0       0            0    0      0     0       \n",
       "3  0           0        ...  1       0            0    0      0     0       \n",
       "4  0           1        ...  1       0            0    0      0     0       \n",
       "5  0           0        ...  0       0            1    0      0     0       \n",
       "6  0           0        ...  0       0            1    0      0     1       \n",
       "\n",
       "   west  written  γωνία  ἕξ  \n",
       "0  0     1        0      0   \n",
       "1  0     0        0      0   \n",
       "2  0     0        1      1   \n",
       "3  1     0        0      0   \n",
       "4  1     0        0      0   \n",
       "5  0     0        0      0   \n",
       "6  0     0        0      0   \n",
       "\n",
       "[7 rows x 69 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words='english')\n",
    "bow_sents = vec.fit_transform(wiki_df[\"text\"]).toarray()\n",
    "bow_df = pd.DataFrame(\n",
    "    data=bow_sents, columns=vec.get_feature_names_out(), index=wiki_df.index\n",
    ")\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d1f6f4-6432-4e07-874b-a09b80eabde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 0, 0, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(bow_sents)\n",
    "kmeans.predict(bow_sents)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e9174d-c281-4bcd-bd8f-8f1cb81e4bd9",
   "metadata": {},
   "source": [
    "KMeans is doing a reasonable job in clustering the sentences because it correctly grouped the language sentences into cluster 0 and the planet sentences into a new cluster 1. However, it incorrectly labeled the shape sentence into the same cluster as the planets and it grouped the fruit sentences into two separate clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02261e6d-8195-4248-9c21-5bc520baa89e",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd1b8be-2c87-48ca-a4a6-2a91f74b8bf2",
   "metadata": {},
   "source": [
    "### 1.3 Sentence embedding representation\n",
    "rubric={points:6}\n",
    "\n",
    "Clustering is sensitive to what kind of representation we use for the given data. \n",
    "Bag-of-words representation is limited in that it does not take into account word ordering and context. There are other richer representations of text, and we are going to use one such representation in this exercise. \n",
    "\n",
    "The code below creates an alternative and a more expressive representation of sentences. We will call it *sentence embedding representation*. We'll use [sentence transformer](https://www.sbert.net/index.html) to extract these representations. At this point it's enough to know that this is an alternative representation of text which usually works better than simple bag-of-words representation. We will talk a bit more about embedding representations next week. You need to install `sentence-transformers` in the course conda environment to run the code below. \n",
    "\n",
    "`conda install -n cpsc330 -c conda-forge sentence-transformers`\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Run the code below and answer the following questions. \n",
    "\n",
    "1. How many dimensions (features associated with each example) are present in this representation? \n",
    "2. Run `KMeans` clustering with sentence embedding representation of text (`emb_sents`) and examine cluster labels. \n",
    "3. How well the sentences are clustered together? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a092544-58d7-418d-84ff-2e898ece2c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cpsc330/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedder = SentenceTransformer(\"paraphrase-distilroberta-base-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20174ee5-9122-4c10-b112-4a675653fee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.169782</td>\n",
       "      <td>0.328721</td>\n",
       "      <td>0.349129</td>\n",
       "      <td>0.160305</td>\n",
       "      <td>-0.001064</td>\n",
       "      <td>-0.042220</td>\n",
       "      <td>0.046996</td>\n",
       "      <td>0.344551</td>\n",
       "      <td>-0.096110</td>\n",
       "      <td>0.152744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094106</td>\n",
       "      <td>0.167671</td>\n",
       "      <td>0.087162</td>\n",
       "      <td>0.102412</td>\n",
       "      <td>0.103286</td>\n",
       "      <td>0.154070</td>\n",
       "      <td>-0.714122</td>\n",
       "      <td>0.529451</td>\n",
       "      <td>-0.081597</td>\n",
       "      <td>-0.048938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.246986</td>\n",
       "      <td>0.277209</td>\n",
       "      <td>0.370583</td>\n",
       "      <td>0.099333</td>\n",
       "      <td>-0.366400</td>\n",
       "      <td>0.168401</td>\n",
       "      <td>0.050352</td>\n",
       "      <td>0.403484</td>\n",
       "      <td>-0.127596</td>\n",
       "      <td>0.240493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015462</td>\n",
       "      <td>-0.115215</td>\n",
       "      <td>0.469176</td>\n",
       "      <td>0.050542</td>\n",
       "      <td>0.079377</td>\n",
       "      <td>0.094788</td>\n",
       "      <td>0.277293</td>\n",
       "      <td>0.399704</td>\n",
       "      <td>0.103588</td>\n",
       "      <td>0.113049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.245753</td>\n",
       "      <td>0.292600</td>\n",
       "      <td>-0.055407</td>\n",
       "      <td>0.269905</td>\n",
       "      <td>-0.148924</td>\n",
       "      <td>0.058779</td>\n",
       "      <td>0.037858</td>\n",
       "      <td>0.228930</td>\n",
       "      <td>0.197867</td>\n",
       "      <td>0.406216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219568</td>\n",
       "      <td>-0.411549</td>\n",
       "      <td>0.049736</td>\n",
       "      <td>0.020908</td>\n",
       "      <td>-0.085819</td>\n",
       "      <td>0.009363</td>\n",
       "      <td>-0.614289</td>\n",
       "      <td>0.260229</td>\n",
       "      <td>0.796774</td>\n",
       "      <td>-0.098542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.043948</td>\n",
       "      <td>0.300679</td>\n",
       "      <td>0.027356</td>\n",
       "      <td>0.522667</td>\n",
       "      <td>0.220695</td>\n",
       "      <td>0.083797</td>\n",
       "      <td>-0.030243</td>\n",
       "      <td>0.330987</td>\n",
       "      <td>0.268973</td>\n",
       "      <td>0.128816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284563</td>\n",
       "      <td>-0.215861</td>\n",
       "      <td>-0.218333</td>\n",
       "      <td>0.225387</td>\n",
       "      <td>0.346727</td>\n",
       "      <td>0.372262</td>\n",
       "      <td>0.022652</td>\n",
       "      <td>0.249070</td>\n",
       "      <td>-0.032098</td>\n",
       "      <td>0.186563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.152196</td>\n",
       "      <td>0.336464</td>\n",
       "      <td>-0.008689</td>\n",
       "      <td>0.666325</td>\n",
       "      <td>0.257241</td>\n",
       "      <td>0.056739</td>\n",
       "      <td>0.087526</td>\n",
       "      <td>0.288248</td>\n",
       "      <td>0.229120</td>\n",
       "      <td>0.134044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661956</td>\n",
       "      <td>0.099084</td>\n",
       "      <td>0.201528</td>\n",
       "      <td>0.048990</td>\n",
       "      <td>0.381907</td>\n",
       "      <td>0.439366</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>-0.068023</td>\n",
       "      <td>0.136935</td>\n",
       "      <td>0.291595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.124167</td>\n",
       "      <td>0.215485</td>\n",
       "      <td>0.013106</td>\n",
       "      <td>0.143410</td>\n",
       "      <td>-0.636150</td>\n",
       "      <td>0.189037</td>\n",
       "      <td>0.114603</td>\n",
       "      <td>0.075671</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>-0.188108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.520294</td>\n",
       "      <td>-0.052253</td>\n",
       "      <td>0.358862</td>\n",
       "      <td>0.229728</td>\n",
       "      <td>0.129429</td>\n",
       "      <td>0.416512</td>\n",
       "      <td>-0.039958</td>\n",
       "      <td>0.330362</td>\n",
       "      <td>-0.018109</td>\n",
       "      <td>0.152335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.071988</td>\n",
       "      <td>0.221728</td>\n",
       "      <td>0.100429</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>-0.170285</td>\n",
       "      <td>-0.222389</td>\n",
       "      <td>0.293238</td>\n",
       "      <td>0.210782</td>\n",
       "      <td>0.178689</td>\n",
       "      <td>0.293481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117664</td>\n",
       "      <td>-0.079962</td>\n",
       "      <td>0.315055</td>\n",
       "      <td>0.144472</td>\n",
       "      <td>0.180411</td>\n",
       "      <td>0.390725</td>\n",
       "      <td>0.426488</td>\n",
       "      <td>0.154363</td>\n",
       "      <td>0.143687</td>\n",
       "      <td>-0.082053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.169782  0.328721  0.349129  0.160305 -0.001064 -0.042220  0.046996   \n",
       "1 -0.246986  0.277209  0.370583  0.099333 -0.366400  0.168401  0.050352   \n",
       "2  0.245753  0.292600 -0.055407  0.269905 -0.148924  0.058779  0.037858   \n",
       "3 -0.043948  0.300679  0.027356  0.522667  0.220695  0.083797 -0.030243   \n",
       "4 -0.152196  0.336464 -0.008689  0.666325  0.257241  0.056739  0.087526   \n",
       "5 -0.124167  0.215485  0.013106  0.143410 -0.636150  0.189037  0.114603   \n",
       "6  0.071988  0.221728  0.100429  0.005925 -0.170285 -0.222389  0.293238   \n",
       "\n",
       "          7         8         9  ...       758       759       760       761  \\\n",
       "0  0.344551 -0.096110  0.152744  ... -0.094106  0.167671  0.087162  0.102412   \n",
       "1  0.403484 -0.127596  0.240493  ...  0.015462 -0.115215  0.469176  0.050542   \n",
       "2  0.228930  0.197867  0.406216  ...  0.219568 -0.411549  0.049736  0.020908   \n",
       "3  0.330987  0.268973  0.128816  ...  0.284563 -0.215861 -0.218333  0.225387   \n",
       "4  0.288248  0.229120  0.134044  ...  0.661956  0.099084  0.201528  0.048990   \n",
       "5  0.075671  0.000973 -0.188108  ... -0.520294 -0.052253  0.358862  0.229728   \n",
       "6  0.210782  0.178689  0.293481  ... -0.117664 -0.079962  0.315055  0.144472   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0  0.103286  0.154070 -0.714122  0.529451 -0.081597 -0.048938  \n",
       "1  0.079377  0.094788  0.277293  0.399704  0.103588  0.113049  \n",
       "2 -0.085819  0.009363 -0.614289  0.260229  0.796774 -0.098542  \n",
       "3  0.346727  0.372262  0.022652  0.249070 -0.032098  0.186563  \n",
       "4  0.381907  0.439366  0.009868 -0.068023  0.136935  0.291595  \n",
       "5  0.129429  0.416512 -0.039958  0.330362 -0.018109  0.152335  \n",
       "6  0.180411  0.390725  0.426488  0.154363  0.143687 -0.082053  \n",
       "\n",
       "[7 rows x 768 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_sents = embedder.encode(wiki_df[\"text\"])\n",
    "emb_sent_df = pd.DataFrame(emb_sents, index=wiki_df.index)\n",
    "emb_sent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe69f2a3-8c0a-4e4d-b049-9709a4aa731e",
   "metadata": {},
   "source": [
    "768 features are present in this representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aacce556-e5fb-4343-92dd-50dda06ca870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 0, 2, 2, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(emb_sents)\n",
    "kmeans.predict(emb_sents)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03470223-f5fb-45c0-9b99-56b2ba506a33",
   "metadata": {},
   "source": [
    "The sentences are clustered together very well as the sentences that are similar are in the appropriate clusters. The fruit sentences are in one cluster (3), the language sentences are in another cluster (2), and the planet sentences are in a third cluster (1). That leaves the single shape sentence in a fourth cluster (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a67c7a-83a4-473a-b710-f31c01f4b6fc",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31e3bb-203e-4877-a54c-eb4f54e0e303",
   "metadata": {},
   "source": [
    "### 1.4 DBSCAN with cosine distance  \n",
    "rubric={points:8}\n",
    "\n",
    "Let's try `DBSCAN` on our toy dataset. K-Means is kind of bound to the Euclidean distance because it is based on the notion of means. With `DBSCAN` we can try different distance metrics. In the context of text (sparse data), [cosine similarities](https://scikit-learn.org/stable/modules/metrics.html#cosine-similarity) or cosine distances tend to work better. Given vectors $u$ and $v$, the **cosine distance** between the vectors is defined as: \n",
    "\n",
    "$$distance_{cosine}(u,v) = 1 - (\\frac{u \\cdot v}{\\left\\lVert u\\right\\rVert_2 \\left\\lVert v\\right\\rVert_2})$$\n",
    "\n",
    "In this exercise, you'll use DBSCAN with cosine distances. \n",
    "\n",
    "**Your tasks**\n",
    "\n",
    "1. Use DBSCAN to cluster our toy data using sentence embedding representation (`emb_sents`) and `metric='cosine'`. \n",
    "2. Briefly comment on the number of clusters identified and the cluster assignment given by the algorithm.\n",
    "\n",
    "> *Note: You will also have to set appropriate values for the hyperparamters `eps` and `min_samples` to get meaningful clusters, as default values for these hyperparameters won't work on this toy dataset. In order to set appropriate value for `eps`, you may want to examine the distances given by [sklearn's `cosine_distance`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_distances.html).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0275d759-744b-43bb-9d8e-a4a87784dc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0, -1,  1,  1,  2,  2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps=0.42, min_samples=2, metric='cosine')\n",
    "dbscan.fit(emb_sents)\n",
    "dbscan.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bf9ec1-010c-4a59-bd5a-2d9e9e6aced5",
   "metadata": {},
   "source": [
    "Three clusters are identified with DBSCAN. Cluster 0 is for the fruit sentences, cluster 1 is for the language sentences, and cluster 2 is for the planet sentences. -1 label represents the shape sentence, which is unassigned to a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f359f90-e90c-4311-adb2-39b6f9a3433c",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30b339-3799-4d4c-b9d5-c0c048243c1f",
   "metadata": {},
   "source": [
    "### 1.5 Visualizing clusters \n",
    "rubric={points:5}\n",
    "\n",
    "One thing we could do with unlabeled data is visualizing it. That said, our data is high dimensional (each example is represented with 768 dimensions) and high-dimensional data is hard to visualize. One way to visualize high-dimensional data is applying dimensionality reduction to get the most important (2 or 3) components of the dataset and visualizing this low-dimensional data. \n",
    "\n",
    "Given data as a `numpy` array and cluster assignments, the `plot_pca_clusters` function below transforms the given data by applying dimensionality reduction and plots the transformed data into corresponding clusters. \n",
    "\n",
    "> *Note: At this point we are using this function only for visualization and you are not expected to understand the PCA part. Feel free to modify the function as you see fit.*\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Call the function `plot_pca_clusters` to visualize the clusters created by the three models above:\n",
    "    - KMeans with bag-of-words representation \n",
    "    - KMeans with sentence embedding representation. \n",
    "    - DBSCAN with sentence embedding representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5531c582-11c4-4691-8110-4ccc7342fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA # Obtain the principal components\n",
    "\n",
    "def plot_pca_clusters(\n",
    "    data,\n",
    "    cluster_labels,\n",
    "    raw_sents=wiki_df[\"text\"],\n",
    "    show_labels=False,\n",
    "    size=100,\n",
    "    title=\"PCA visualization\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Carry out dimensionality reduction using PCA and plot 2-dimensional clusters.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    data : numpy array\n",
    "        data as a numpy array\n",
    "    cluster_labels : list\n",
    "        cluster labels for each row in the dataset\n",
    "    raw_sents : list\n",
    "        the original raw sentences for labeling datapoints\n",
    "    show_labels : boolean\n",
    "        whether you want to show labels for points or not (default: False)\n",
    "    size : int\n",
    "        size of points in the scatterplot\n",
    "    title : str\n",
    "        title for the visualization plot\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    None. Shows the clusters.\n",
    "    \"\"\"\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    principal_comp = pca.fit_transform(data)\n",
    "    pca_df = pd.DataFrame(data=principal_comp, columns=[\"pca1\", \"pca2\"])\n",
    "    pca_df[\"cluster\"] = cluster_labels\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.title(title)\n",
    "    ax = sns.scatterplot(\n",
    "        x=\"pca1\", y=\"pca2\", hue=\"cluster\", data=pca_df, palette=\"tab10\", s=size\n",
    "    )\n",
    "\n",
    "    x = pca_df[\"pca1\"].tolist()\n",
    "    y = pca_df[\"pca2\"].tolist()\n",
    "    if show_labels:\n",
    "        for i, txt in enumerate(raw_sents):\n",
    "            plt.annotate(\" \".join(txt.split()[:10]), (x[i], y[i]))\n",
    "        ax.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "510b3714-a182-4257-9d03-acb03a1afd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pca_clusters(\n",
    "    bow_sents,\n",
    "    kmeans.labels_,\n",
    "    raw_sents=wiki_df[\"text\"],\n",
    "    show_labels=False,\n",
    "    size=100,\n",
    "    title=\"PCA visualization of KMeans with bag-of-words representation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8252f13-4c69-4011-bcb0-e6f016c8a1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pca_clusters(\n",
    "    emb_sents,\n",
    "    kmeans.labels_,\n",
    "    raw_sents=wiki_df[\"text\"],\n",
    "    show_labels=False,\n",
    "    size=100,\n",
    "    title=\"PCA visualization of KMeans with sentence embedding representation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2aef572-edab-4927-8edc-00e591819af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pca_clusters(\n",
    "    emb_sents,\n",
    "    dbscan.labels_,\n",
    "    raw_sents=wiki_df[\"text\"],\n",
    "    show_labels=False,\n",
    "    size=100,\n",
    "    title=\"PCA visualization of DBSCAN with sentence embedding representation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bf74a4-86f7-479f-ac54-4fbd0709b126",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d135d-cf62-4a8c-990d-631ee1662913",
   "metadata": {},
   "source": [
    "## Exercise 2: Movie recommendations\n",
    "<hr>\n",
    "\n",
    "Let's build simple movie recommendation systems using the [MovieLens dataset](https://www.kaggle.com/prajitdatta/movielens-100k-dataset/data). The original source of the data is [here](https://grouplens.org/datasets/movielens/), and the structure of the data is described in the [README](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html) that comes with it. The code below reads the data as a CSV assuming that it's under `ml-100k/` directory under your homework folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41780f0a-8c8d-4baf-8059-cf428dad85cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0  196      242       3       881250949\n",
       "1  186      302       3       891717742\n",
       "2  22       377       1       878887116\n",
       "3  244      51        2       880606923\n",
       "4  166      346       1       886397596"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cols = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "ratings = pd.read_csv(\n",
    "    os.path.join(\"ml-100k\", \"u.data\"),\n",
    "    sep=\"\\t\",\n",
    "    names=r_cols,\n",
    "    encoding=\"latin-1\",\n",
    ")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "206ca960-e598-48ba-b506-3710e3714047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be using these keys later in the starter code\n",
    "user_key = \"user_id\"\n",
    "item_key = \"movie_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbd1906-2d3f-4da0-af80-4ff5be61b3d0",
   "metadata": {},
   "source": [
    "### 2.1 Terminology\n",
    "rubric={points:3}\n",
    "\n",
    "Here is some notation we will be using in this homework. \n",
    "\n",
    "**Constants**:\n",
    "\n",
    " - $N$: the number of users, indexed by $n$\n",
    " - $M$: the number of movies, indexed by $m$\n",
    " - $\\mathcal{R}$: the set of indices $(n,m)$ where we have ratings in the utility matrix $Y$\n",
    "    - Thus $|\\mathcal{R}|$ is the total number of ratings\n",
    " \n",
    "**The data**:\n",
    "\n",
    " - $Y$: the utility matrix containing ratings, with a lot of missing entries\n",
    " - `train_mat` and `valid_mat`: Utility matrices for train and validation sets, respectively\n",
    " \n",
    "    \n",
    "**Your tasks:**    \n",
    "\n",
    "1. What are the values of $N$ and $M$ in movie ratings data?  \n",
    "2. What would be the shape of the dense utility matrix $Y$? \n",
    "3. What would be the fraction of non missing ratings in the utility matrix $Y$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40744eb3-0f31-4237-934e-4694fa82192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users (N): 943\n",
      "Number of items (M): 1682\n",
      "Shape of dense utility matrix (Y): (943, 1682)\n",
      "Fraction non-nan ratings: 0.063\n"
     ]
    }
   ],
   "source": [
    "N = len(np.unique(ratings[user_key]))\n",
    "M = len(np.unique(ratings[item_key]))\n",
    "\n",
    "print(\"Number of users (N): %d\" % N)\n",
    "print(\"Number of items (M): %d\" % M)\n",
    "print(\"Shape of dense utility matrix (Y): (\" + str(N) + \", \" + str(M) + \")\")\n",
    "print(\"Fraction non-nan ratings: %0.3f\" % (len(ratings) / (N * M)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c433a44-37b9-4113-8102-10d918cc84ac",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc74ee-cc48-4e73-b8ba-0bcdc84d3380",
   "metadata": {},
   "source": [
    "### 2.2 Splitting the data\n",
    "rubric={points:5}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the ratings data with `test_size=0.2` and `random_state=42`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aafd196-cdec-458d-a9d6-2d637406d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = ratings.copy()\n",
    "y = ratings[user_key]  \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1526cf-a7e5-425e-b8e5-dd8cadb53a50",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb483ab-ae9a-4d3d-a2d5-be404c422c14",
   "metadata": {},
   "source": [
    "### 2.3 Utility matrix \n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks**\n",
    "1. Create utility matrices for train and validation sets. \n",
    "2. Briefly explain the difference between the train and validation utility matrices. \n",
    "\n",
    "> You may use the code from lecture notes with appropriate attributions.  \n",
    "\n",
    "> You won't do it in real life but since our dataset is not that big, create a dense utility matrix in this assignment. You are welcome to try sparse matrix but then you may have to change some started code provided in the later exercises.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9b8d514-615a-4166-b597-eee2e53dbfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper = dict(zip(np.unique(ratings[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(ratings[item_key]), list(range(M))))\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(ratings[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(ratings[item_key])))\n",
    "\n",
    "# from lecture 15\n",
    "def create_Y_from_ratings(data, N, M):\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"rating\"]\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "192d8a08-c194-45c2-83ca-63156311401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat = create_Y_from_ratings(X_train, N, M)\n",
    "valid_mat = create_Y_from_ratings(X_valid, N, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d1e07b-b1ea-4487-bd23-dd6012f67f05",
   "metadata": {},
   "source": [
    "The difference between the train and validation utility matrices is that train_mat has only ratings from the train set and valid_mat has only ratings from the valid set because during training we do not have access to some of the available ratings, so we predict these ratings and evaluate them against ratings in the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce90c62-f51b-4c35-a136-52176cbf8ea3",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0597e68-8a04-4779-b3d2-f23a829879b3",
   "metadata": {},
   "source": [
    "### 2.4 Evaluation and baseline\n",
    "rubric={points:4}\n",
    "\n",
    "To compare different models you build in this homework, let's write a couple of functions for evaluation. \n",
    "- The `error` function returns RMSE.\n",
    "- The `evaluate` function prints the train and validation RMSEs. \n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Briefly explain what exactly we are comparing to evaluate recommender systems. \n",
    "2. Implement the global average baseline, where you predict everything as the global average rating. What's the RMSE of the global average baseline?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a4b8ae-f229-4b1e-95c7-280cb2b59f87",
   "metadata": {},
   "source": [
    "We are comparing the actual ratings and predicted ratings by calculating the error between them using the RMSE metric to evaluate recommender systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15c3c76a-5d5b-4773-a48c-0f26d5ec5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Returns the root mean squared error (RMSE).\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean((Y1 - Y2) ** 2))\n",
    "\n",
    "\n",
    "def evaluate(pred_Y, train_mat, valid_mat, model_name=\"Global average\"):\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_Y, train_mat)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_Y, valid_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cf256a8-a898-4399-b3f3-d5e753dc1e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1672</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "1  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "2  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "3  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "4  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "\n",
       "          7         8         9  ...      1672      1673      1674      1675  \\\n",
       "0  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "1  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "2  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "3  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "4  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "\n",
       "       1676      1677      1678      1679      1680      1681  \n",
       "0  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "1  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "2  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "3  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "4  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "\n",
       "[5 rows x 1682 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from lecture 15\n",
    "avg = np.nanmean(train_mat)\n",
    "pred_g = np.zeros(train_mat.shape) + avg\n",
    "pd.DataFrame(pred_g).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae285be8-dfe1-4980-a079-c39f598c88a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 1.13\n",
      "Global average valid RMSE: 1.12\n"
     ]
    }
   ],
   "source": [
    "evaluate(pred_g, train_mat, valid_mat, model_name=\"Global average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a6ab6-62ef-4fdd-ba0d-5e7e920154a3",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a02d5-bf63-428a-8bac-9fa6f2f38681",
   "metadata": {},
   "source": [
    "### (Optional) 2.5 $k$-nearest neighbours imputation\n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Try [KNNImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html) to fill in the missing entries. Discuss your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a7790d-8824-40a2-9b79-9d3c7a647757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbours: 10':        0    1    2    3    4    5    6    7    8    9  ...  1643  1644  1645  \\\n",
       " 0    4.0  3.0  4.0  3.7  3.0  3.8  4.0  3.3  5.0  3.0  ...  3.0   3.0   1.0    \n",
       " 1    4.0  3.0  3.3  4.1  3.2  4.3  4.4  4.4  4.5  4.1  ...  3.0   3.0   1.0    \n",
       " 2    3.8  3.2  2.8  3.1  3.5  3.5  4.0  3.7  3.7  4.3  ...  3.0   3.0   1.0    \n",
       " 3    4.1  2.9  3.9  3.1  3.6  3.8  3.3  4.3  4.2  4.2  ...  3.0   3.0   1.0    \n",
       " 4    4.0  3.0  3.3  3.8  3.3  4.1  4.0  3.8  3.8  4.1  ...  3.0   3.0   1.0    \n",
       " ..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...    \n",
       " 938  3.8  3.7  3.7  3.5  4.0  4.1  4.0  3.9  5.0  4.3  ...  3.0   3.0   1.0    \n",
       " 939  4.1  3.2  3.6  2.0  3.3  3.6  3.7  4.1  3.0  4.3  ...  3.0   3.0   1.0    \n",
       " 940  5.0  3.4  2.9  3.8  3.3  3.6  4.3  3.8  4.5  3.6  ...  3.0   3.0   1.0    \n",
       " 941  4.2  3.4  3.6  3.4  4.0  4.0  3.5  4.3  4.0  4.0  ...  3.0   3.0   1.0    \n",
       " 942  4.3  5.0  3.2  3.6  3.3  4.0  3.7  4.4  3.0  4.1  ...  3.0   3.0   1.0    \n",
       " \n",
       "      1646  1647  1648  1649  1650  1651  1652  \n",
       " 0    2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 1    2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 2    2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 3    2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 4    2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " ..   ...   ...   ...   ...   ...   ...   ...   \n",
       " 938  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 939  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 940  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 941  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 942  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " \n",
       " [943 rows x 1653 columns],\n",
       " 'n_neighbours: 15':             0         1         2         3         4         5         6  \\\n",
       " 0    3.933333  3.000000  4.000000  3.733333  3.000000  3.933333  4.000000   \n",
       " 1    4.000000  3.200000  3.266667  3.866667  3.266667  3.733333  4.266667   \n",
       " 2    3.800000  3.400000  2.666667  3.266667  3.333333  3.666667  4.066667   \n",
       " 3    4.133333  3.200000  3.533333  3.200000  3.600000  3.466667  3.333333   \n",
       " 4    4.000000  2.866667  3.000000  3.733333  3.333333  3.800000  3.933333   \n",
       " ..        ...       ...       ...       ...       ...       ...       ...   \n",
       " 938  4.000000  3.933333  3.733333  3.733333  3.800000  3.733333  3.933333   \n",
       " 939  4.133333  3.133333  3.266667  2.000000  3.266667  3.533333  3.733333   \n",
       " 940  5.000000  3.400000  3.066667  3.666667  3.466667  3.733333  4.066667   \n",
       " 941  4.200000  3.466667  3.400000  3.466667  3.733333  3.733333  3.400000   \n",
       " 942  4.266667  5.000000  3.266667  3.466667  3.333333  3.733333  3.666667   \n",
       " \n",
       "             7         8         9  ...  1643  1644  1645  1646  1647  1648  \\\n",
       " 0    3.666667  5.000000  3.000000  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 1    4.066667  4.333333  3.866667  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 2    3.800000  3.866667  4.266667  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 3    4.000000  4.066667  4.066667  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 4    3.800000  3.800000  3.866667  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " ..        ...       ...       ...  ...  ...   ...   ...   ...   ...   ...    \n",
       " 938  4.133333  5.000000  4.133333  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 939  3.800000  3.000000  4.400000  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 940  4.000000  4.466667  3.866667  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 941  4.400000  4.200000  4.000000  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 942  4.066667  3.000000  3.800000  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " \n",
       "      1649  1650  1651  1652  \n",
       " 0    1.0   3.0   2.0   3.0   \n",
       " 1    1.0   3.0   2.0   3.0   \n",
       " 2    1.0   3.0   2.0   3.0   \n",
       " 3    1.0   3.0   2.0   3.0   \n",
       " 4    1.0   3.0   2.0   3.0   \n",
       " ..   ...   ...   ...   ...   \n",
       " 938  1.0   3.0   2.0   3.0   \n",
       " 939  1.0   3.0   2.0   3.0   \n",
       " 940  1.0   3.0   2.0   3.0   \n",
       " 941  1.0   3.0   2.0   3.0   \n",
       " 942  1.0   3.0   2.0   3.0   \n",
       " \n",
       " [943 rows x 1653 columns],\n",
       " 'n_neighbours: 20':         0     1     2     3     4         5     6     7     8     9  ...  \\\n",
       " 0    3.90  3.00  4.00  3.75  3.00  3.647059  4.00  3.70  5.00  3.00  ...   \n",
       " 1    4.00  3.30  3.35  3.90  3.20  3.647059  4.30  4.10  4.30  3.95  ...   \n",
       " 2    3.95  3.35  2.70  3.20  3.25  3.647059  4.00  3.70  3.80  4.15  ...   \n",
       " 3    4.00  3.15  3.40  3.35  3.50  3.647059  3.40  3.90  4.00  4.10  ...   \n",
       " 4    4.00  2.90  3.00  3.65  3.20  3.647059  4.00  3.75  3.55  3.90  ...   \n",
       " ..    ...   ...   ...   ...   ...       ...   ...   ...   ...   ...  ...   \n",
       " 938  3.95  3.90  3.65  3.80  3.65  3.647059  3.95  4.20  5.00  4.05  ...   \n",
       " 939  4.10  3.15  3.10  2.00  3.20  3.647059  3.90  3.65  3.00  4.10  ...   \n",
       " 940  5.00  3.35  3.25  3.70  3.55  3.647059  4.15  4.10  4.25  3.90  ...   \n",
       " 941  4.15  3.40  3.20  3.50  3.65  3.647059  3.35  4.35  4.15  3.90  ...   \n",
       " 942  4.20  5.00  3.40  3.60  3.25  3.647059  3.65  4.00  3.00  3.90  ...   \n",
       " \n",
       "      1643  1644  1645  1646  1647  1648  1649  1650  1651  1652  \n",
       " 0    3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 1    3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 2    3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 3    3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 4    3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " ..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       " 938  3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 939  3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 940  3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 941  3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 942  3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " \n",
       " [943 rows x 1653 columns],\n",
       " 'n_neighbours: 25':         0     1     2     3     4         5     6     7     8     9  ...  \\\n",
       " 0    3.92  3.00  4.00  3.72  3.00  3.647059  4.00  3.80  5.00  3.00  ...   \n",
       " 1    4.00  3.20  3.16  3.72  3.28  3.647059  4.28  4.24  4.40  4.00  ...   \n",
       " 2    3.96  3.28  2.88  3.28  3.24  3.647059  3.96  3.76  3.92  4.00  ...   \n",
       " 3    3.92  3.24  3.24  3.32  3.44  3.647059  3.44  4.00  3.96  4.12  ...   \n",
       " 4    4.00  2.96  2.96  3.48  3.16  3.647059  3.96  3.88  3.76  3.80  ...   \n",
       " ..    ...   ...   ...   ...   ...       ...   ...   ...   ...   ...  ...   \n",
       " 938  3.88  3.84  3.48  3.88  3.60  3.647059  4.12  4.16  5.00  4.00  ...   \n",
       " 939  4.04  3.16  3.16  2.00  3.20  3.647059  3.76  3.76  3.00  4.08  ...   \n",
       " 940  5.00  3.24  3.40  3.64  3.60  3.647059  4.04  4.12  4.24  3.88  ...   \n",
       " 941  4.16  3.36  3.32  3.60  3.56  3.647059  3.40  4.36  4.20  3.88  ...   \n",
       " 942  4.00  5.00  3.24  3.68  3.32  3.647059  3.80  4.04  3.00  3.88  ...   \n",
       " \n",
       "      1643  1644  1645  1646  1647  1648  1649  1650  1651  1652  \n",
       " 0    3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 1    3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 2    3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 3    3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 4    3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " ..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       " 938  3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 939  3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 940  3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 941  3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " 942  3.0   3.0   1.0   2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       " \n",
       " [943 rows x 1653 columns],\n",
       " 'n_neighbours: 30':             0         1         2         3         4         5         6  \\\n",
       " 0    3.900000  3.000000  4.000000  3.766667  3.000000  3.647059  4.000000   \n",
       " 1    4.000000  3.200000  3.166667  3.700000  3.266667  3.647059  4.233333   \n",
       " 2    4.033333  3.333333  2.833333  3.333333  3.266667  3.647059  3.966667   \n",
       " 3    3.933333  3.300000  3.200000  3.433333  3.266667  3.647059  3.500000   \n",
       " 4    4.000000  2.900000  2.800000  3.466667  3.166667  3.647059  3.800000   \n",
       " ..        ...       ...       ...       ...       ...       ...       ...   \n",
       " 938  3.933333  3.700000  3.400000  3.766667  3.500000  3.647059  4.233333   \n",
       " 939  4.033333  3.233333  3.200000  2.000000  3.266667  3.647059  3.733333   \n",
       " 940  5.000000  3.300000  3.433333  3.633333  3.466667  3.647059  4.033333   \n",
       " 941  4.033333  3.433333  3.166667  3.700000  3.633333  3.647059  3.300000   \n",
       " 942  3.966667  5.000000  3.166667  3.733333  3.333333  3.647059  3.833333   \n",
       " \n",
       "             7         8         9  ...  1643  1644  1645  1646  1647  1648  \\\n",
       " 0    3.900000  5.000000  3.000000  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 1    4.133333  4.433333  4.033333  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 2    3.666667  3.833333  4.066667  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 3    4.066667  3.966667  4.233333  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 4    3.933333  3.733333  3.833333  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " ..        ...       ...       ...  ...  ...   ...   ...   ...   ...   ...    \n",
       " 938  4.033333  5.000000  4.000000  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 939  3.866667  3.000000  4.033333  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 940  4.166667  4.266667  3.866667  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 941  4.366667  4.166667  3.900000  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " 942  3.966667  3.000000  4.000000  ...  3.0   3.0   1.0   2.0   3.0   2.0    \n",
       " \n",
       "      1649  1650  1651  1652  \n",
       " 0    1.0   3.0   2.0   3.0   \n",
       " 1    1.0   3.0   2.0   3.0   \n",
       " 2    1.0   3.0   2.0   3.0   \n",
       " 3    1.0   3.0   2.0   3.0   \n",
       " 4    1.0   3.0   2.0   3.0   \n",
       " ..   ...   ...   ...   ...   \n",
       " 938  1.0   3.0   2.0   3.0   \n",
       " 939  1.0   3.0   2.0   3.0   \n",
       " 940  1.0   3.0   2.0   3.0   \n",
       " 941  1.0   3.0   2.0   3.0   \n",
       " 942  1.0   3.0   2.0   3.0   \n",
       " \n",
       " [943 rows x 1653 columns]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from lecture 15\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "results_dict = {}\n",
    "neighbours = [10, 15, 20, 25, 30]\n",
    "\n",
    "for n in neighbours:\n",
    "    imputer = KNNImputer(n_neighbors=n)\n",
    "    train_mat_imp = imputer.fit_transform(train_mat)\n",
    "    results_dict[\"n_neighbours: \" + str(n)] = pd.DataFrame(train_mat_imp)\n",
    "\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f727b0da-aa2b-4d2a-b186-c753161732ed",
   "metadata": {},
   "source": [
    "The new matrices formed after imputation have less columns than the original utility matrix because KNNImputer removes all the columns with all NaN values. The shape before imputing was (943, 1682), but now it is (943, 1653)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff65bf17-79e9-4b85-9739-bfc9faf540fa",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf229e-5817-4d76-a5e9-e492bbb9efd3",
   "metadata": {},
   "source": [
    "### 2.6 Use collaborative filtering with the `surprise` package\n",
    "rubric={points:6}\n",
    "\n",
    "Use the [`surprise`](https://surprise.readthedocs.io/en/stable/) package which has implementation of SVD algorithm for collaborative filtering. You can install it as follows in your conda environment. \n",
    "\n",
    "`conda install -n cpsc330 -c conda-forge scikit-surprise`\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out cross-validation using SVD algorithm in the package, similar to how we did it in the lecture on Jester dataset. Report mean RMSE and compare it with global baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d543c-c5fc-4194-b91b-dda2046d0c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9328\n",
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9386  0.9323  0.9391  0.9385  0.9318  0.9360  0.0033  \n",
      "MAE (testset)     0.7428  0.7357  0.7405  0.7391  0.7369  0.7390  0.0025  \n",
      "Fit time          1.77    1.93    1.75    1.99    1.79    1.85    0.10    \n",
      "Test time         0.14    0.13    0.11    0.11    0.12    0.13    0.01    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test_rmse    0.936049\n",
       "test_mae     0.738988\n",
       "fit_time     1.846936\n",
       "test_time    0.125040\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from lecture 15\n",
    "import surprise\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "\n",
    "ratings_surprise = ratings.drop([\"timestamp\"], axis=1)\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(ratings_surprise, reader)  \n",
    "\n",
    "\n",
    "trainset, validset = surprise.model_selection.train_test_split(\n",
    "    data, test_size=0.2, random_state=42\n",
    ")  \n",
    "\n",
    "k = 10\n",
    "svd_algo = SVD(n_factors=k, random_state=42)\n",
    "svd_algo.fit(trainset)\n",
    "svd_preds = svd_algo.test(validset)\n",
    "accuracy.rmse(svd_preds, verbose=True)\n",
    "\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "results = cross_validate(svd_algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)\n",
    "pd.DataFrame(results).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be63c1f7-82d3-4532-82d7-2d55c8f596d5",
   "metadata": {},
   "source": [
    "The mean RMSE is 0.9360, whereas the RMSE for the global baseline is 1.12. This is lower than the global baseline's RMSE which tells us that the model is not overfitting and can fit the dataset well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a044157f-1236-4cb9-8c76-82647f23cc99",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d184a9-7fad-4e34-8fa7-b10443d83911",
   "metadata": {},
   "source": [
    "## Exercise 3: Short answer questions\n",
    "<hr>\n",
    "\n",
    "rubric={points:5}\n",
    "\n",
    "Answer the following short-answer questions: \n",
    "\n",
    "1. What's the main difference between unsupervised and supervised learning?\n",
    "2. When choosing $k$ in $k$-means, why not just choose the $k$ that leads to the smallest inertia (sum of squared distances within clusters)?\n",
    "3. You decide to use clustering for _outlier detection_; that is, to detect instances that are very atypical compared to all the rest. How might you do this with $k$-means?\n",
    "4. You decide to use clustering for _outlier detection_; that is, to detect instances that are very atypical compared to all the rest. How might you do this with DBSCAN?\n",
    "5. How might you apply clustering to recommendation systems? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43410bc8-d121-4da6-997b-b84cbf419e16",
   "metadata": {},
   "source": [
    "1. The main difference between unsupervised and supervised learning is that in supervised learning we have labeled data and in unsupervised learning we have unlabeled data. We do not have a target class in unsupervised learning.\n",
    "\n",
    "2. We cannot just choose the $k$ that leads to the smallest inertia because the inertia decreases as K increases. For example, if number of clusters equals number of examples, each example will have its own cluster and the intra-cluster distance will be 0.\n",
    "\n",
    "3. With $k$-means, each cluster is represented by a center. We assign each example to the closest center and estimate new centers as an average of observations in a cluster or until centers stop changing or maximum iterations have reached. This iterative process can detect outliers as it updates the center every step, allowing us to visualize which points are not close to it.\n",
    "\n",
    "4. We can detect outliers by increasing eps because either more points will be included in a cluster or noise points will be created. We can also increase min_samples since points in less dense regions will either be labeled as their own cluster or noise.\n",
    "\n",
    "5. We can apply clustering to recommendation systems by using $k$-means or DBSCAN to find new recommendations for something through observing a user's past preferences based on a center. When we assign new points to a center, it can represent a new recommendation we create to offer a user. This can increase the diversity, consistency, and reliability of recommendations, as well as the data sparsity of user-preference matrices and changes in user preferences over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea9c37-34c9-4b3e-a2df-e00cedd3e8ae",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab723dc5-4ea6-4c44-ace9-bf345bf8c120",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
